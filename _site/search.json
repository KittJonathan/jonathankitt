[
  {
    "objectID": "posts/2024-08-22-datardis-0-0-5/index.html",
    "href": "posts/2024-08-22-datardis-0-0-5/index.html",
    "title": "{datardis} package v.0.0.5",
    "section": "",
    "text": "Introduction\n\nThe {datardis} package includes datasets which provide lists of episodes for the Doctor Who and Torchwood TV series.\nThe latest version of the package (v.0.0.5) includes the latest episodes :\n\n2023 specials\n\nSeries 14 (2024)\n\n\n\n\nInstalling the package\n\nTo install the latest version of the package, use the following command:\n\n# üîΩ INSTALL THE PACKAGE --------------------------------------------------\n\ninstall.packages(\"datardis\")\n\n\nAlternatively, you can install the package from GitHub using {devtools} :\n\ndevtools::install_github(\"KittJonathan/datardis\")\n\n\n\n\nLoading the packages\n\nFirst of all, let‚Äôs load the packages we‚Äôll be using :\n\n{datardis}\n{tidyverse} to clean the data and create the plots\n{showtext} to add custom fonts\n\nIf you don‚Äôt have the packages installed, simply use the install.packages(\"...\") function.\n\n\n# üì¶ LOAD THE PACKAGES ----------------------------------------------------\n\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(datardis)\n\n\n\n\nCleaning the data\n\nWe use the following code to clean the data:\n\n# üßπ  Clean the data ----\n\nd &lt;- drwho_episodes |&gt; \n  filter(year(first_aired) &gt;= 2023) |&gt; \n  select(episode_number, type, episode_title, first_aired, uk_viewers, duration) |&gt; \n  mutate(uk_viewers = as.numeric(uk_viewers),\n         episode_title = case_when(type == \"special\" ~ paste0(episode_title, \" *\"),\n                                   .default = episode_title),\n         episode_title = fct_rev(fct_inorder(episode_title)))\n\nd\n\n# A tibble: 12 √ó 6\n   episode_number type    episode_title          first_aired uk_viewers duration\n            &lt;int&gt; &lt;chr&gt;   &lt;fct&gt;                  &lt;date&gt;           &lt;dbl&gt;    &lt;dbl&gt;\n 1              1 special The Star Beast *       2023-11-25        7.61       57\n 2              2 special Wild Blue Yonder *     2023-12-02        7.14       54\n 3              3 special The Giggle *           2023-12-09        6.85       62\n 4             NA special The Church on Ruby Ro‚Ä¶ 2023-12-25        7.49       55\n 5              1 episode Space Babies           2024-05-11        4.01       46\n 6              2 episode The Devil's Chord      2024-05-11        3.91       49\n 7              3 episode Boom                   2024-05-18        3.58       44\n 8              4 episode 73 Yards               2024-05-25        4.06       47\n 9              5 episode Dot and Bubble         2024-06-01        3.38       43\n10              6 episode Rogue                  2024-06-08        3.52       44\n11              7 episode The Legend of Ruby Su‚Ä¶ 2024-06-15        3.5        44\n12              8 episode Empire of Death        2024-06-22        3.69       54\n\n\n\n\n\nCreating the plot\n\nWe use the following code to create the plot :\n\n# üìä CREATE THE PLOT ------------------------------------------------------\n\np &lt;- d |&gt; \n  ggplot() +\n  geom_segment(aes(x = 0, xend = uk_viewers,\n                   y = episode_title, yend = episode_title),\n               colour = \"#a6b8c7\") +\n  geom_point(aes(x = uk_viewers, y = episode_title),\n             shape = 21, size = 10, fill = \"#00203c\", colour = \"#a6b8c7\") +\n  geom_text(aes(x = uk_viewers, y = episode_title, label = uk_viewers),\n            hjust = 0.5, family = \"Roboto Condensed\", size = 10, colour = \"white\") +\n  geom_text(aes(x = 0, y = episode_title, label = episode_title),\n            hjust = 0, vjust = -0.5, family = \"Roboto Condensed\",\n            size = 14, colour = \"white\") +\n  geom_segment(aes(x = -0.25, xend = -0.25, y = 9.75, yend = 12.25),\n               colour = \"#a6b8c7\", linewidth = 1) +\n  geom_segment(aes(x = -0.25, xend = -0.25, y = 0.75, yend = 9.25),\n              colour = \"#a6b8c7\", linewidth = 1) +\n  geom_text(aes(x = -0.5, y = 11, label = \"2023 specials\"),\n            hjust = 0.5, family = \"Roboto Condensed\", size = 18, colour = \"white\",\n            angle = 90) +\n  geom_text(aes(x = -0.5, y = 5, label = \"14th series\"),\n            hjust = 0.5, family = \"Roboto Condensed\", size = 18, colour = \"white\",\n            angle = 90) +\n  labs(title = \"Number of UK viewers of Doctor Who episodes (in millions)\",\n       subtitle = \"Special episodes are noted with a *\") +\n  theme_minimal() +\n  theme(axis.title = element_blank(),\n        axis.text = element_blank(),\n        panel.background = element_rect(colour = \"#00203c\",\n                                        fill = \"#00203c\"),\n        panel.grid = element_blank(),\n        plot.background = element_rect(colour = \"#00203c\",\n                                       fill = \"#00203c\"),\n        plot.title = element_text(family = \"Roboto Condensed\",\n                                  colour = \"white\", size = 50, hjust = 0.5,\n                                  margin = margin(t = 5, b = 5)),\n        plot.subtitle = element_text(family = \"Roboto Condensed\",\n                                  colour = \"white\", size = 30, hjust = 0.5))\n\n\n\n\nSave the plot\n\nWe use the following code to export the plot to a .png file :\n\n# üíæ EXPORT THE PLOT ------------------------------------------------------\n\nggsave(\"img/drwho_viewers.png\", p,\n       dpi = 320, width = 12, height = 6)\n\n\nAnd here‚Äôs the result!"
  },
  {
    "objectID": "posts/2023-08-29-tt-fair-use/index.html",
    "href": "posts/2023-08-29-tt-fair-use/index.html",
    "title": "#TidyTuesday 2023 - Week 35",
    "section": "",
    "text": "Thanls to Dan Oehm for sharing his tips on addind icons in the script titles!\n\nIntroduction\n\nThe #TidyTuesday weekly challenge is organised by the R4DS (R for Data Science) Online Learning Community.\nEvery tuesday throughout the year, participants work on a common dataset and share the plots they create.\nThe dataset for this challenge comes from the U.S. Copyright Office Fair Use Index.\n\n\n\nGetting the data\n\nFirst of all, let‚Äôs load the packages we‚Äôll be using :\n\n{tidyverse} to clean the data and create the plots\n{showtext} to change the fonts used\n{ggtext} to use colours in the title\n\nIf you don‚Äôt have these packages installed, simply use the install.packages() function.\n\n# üì¶ Load packages ----\n\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(ggtext)\n\n\nWe also load the fonts we will use in the plots: Bebas Neue for the text and Londrina Shadow for the title.\n\n# üî§ Import fonts ----\n\nfont_add_google(\"Roboto Condensed\", \"Roboto Condensed\")\nshowtext_auto()\n\n\nWe can now download the dataset :\n\n# ‚¨áÔ∏è Import the dataset ----\n\nfair_use_cases &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-29/fair_use_cases.csv\")\n\n\nThe dataset has 251 observations (rows) and 7 variables (columns).\n\n\n\nCleaning the data\n\nWe use the following code to clean the data:\n\n# üßπ  Clean the data ----\n\nd &lt;- fair_use_cases |&gt;\n  # keep years 2013-2022\n  filter(year &gt;= 2013) |&gt;\n  # count number of found/not found cases per year\n  count(year, fair_use_found) |&gt;\n  # repeat each row n times (n = nb of occurences)\n  uncount(n) |&gt;\n  # create a row index\n  mutate(case_id = 1:n(), .by = c(year, fair_use_found)) |&gt;\n  # use negative values for \"not found\" cases\n  mutate(y = case_when(fair_use_found == TRUE ~ case_id,\n                       TRUE ~ -case_id))\n\n\n\n\nCreating the plot\n\nWe use the following code to create the plot:\n\np &lt;- ggplot(data = d) +\n  geom_point(aes(x = year, y = y,\n                 colour = fair_use_found),\n             shape = 21, size = 6,\n             show.legend = FALSE) +\n  geom_text(aes(x = year, y = y,\n                colour = fair_use_found),\n            label = \"C\",\n            family = \"Roboto Condensed\", size = 12,\n            show.legend = FALSE) +\n  geom_text(aes(x = year, y = 0, label = year),\n            family = \"Roboto Condensed\", size = 15,\n            colour = \"white\") +\n  scale_colour_manual(values = c(\"#fd574a\", \"#2eed91\")) +\n  labs(title = \"Number of fair use court cases in the U.S. (2013-2022)\",\n       subtitle = \"Colours indicate whether fair use was&lt;span style='color:#2eed91;'&gt; found&lt;/span&gt; or &lt;span style='color:#fd574a;'&gt;not found&lt;/span&gt; by the court\",\n       caption = \"#TidyTuesday 2023 week 35 | Data from the U.S. Copyright Office Fair Use Index | Jonathan Kitt\") +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"black\", colour = \"black\"),\n        plot.background = element_rect(fill = \"black\", colour = \"black\"),\n        plot.title = element_markdown(family = \"Roboto Condensed\",\n                                      colour = \"white\", size = 75,\n                                      margin = margin(t = 20, l = 20)),\n        plot.subtitle = element_markdown(family = \"Roboto Condensed\",\n                                         colour = \"white\", size = 50,\n                                         margin = margin(t= 5, l = 20)),\n        plot.caption = element_text(family = \"Roboto Condensed\",\n                                    colour = \"white\", size = 30,\n                                    hjust = 0.5, margin = margin(t = 10, b = 10)))\n\n\nWe now create the second plot:\n\n# ‚úèÔ∏è Create the plot ----\n\np2 &lt;- ggplot() +\n  geom_rect(data = p2_scores,\n             aes(xmin = x - 0.85, xmax = x + 0.85,\n                 ymin = 0, ymax = total_thsd),\n            fill = \"#edeb00\") +\n  geom_text(data = p2_scores,\n            aes(x = x, y = total_thsd - 160, label = total_thsd),\n            family = \"Bebas Neue\", colour = \"black\", size = 18) +\n  geom_text(data = p2_x_labels,\n            aes(x = x, y = y, label = label),\n            family = \"Bebas Neue\", colour = \"white\", size = 18) +\n  geom_text(data = p2_text,\n            aes(x = x, y = y, label = label),\n            family = \"Bebas Neue\", colour = \"white\", size = 20,\n            hjust = 0) +\n  xlim(-1, 46) +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"black\"),\n        plot.background = element_rect(fill = \"black\"))\n\n# üíæ Export plot ----\n\nggsave(\"figs/tt_2023_w35_fair_use.png\", p, dpi = 320, width = 12, height = 6)\n\n\nAnd here‚Äôs the result!"
  },
  {
    "objectID": "posts/2023-08-04-tt-us/index.html",
    "href": "posts/2023-08-04-tt-us/index.html",
    "title": "#TidyTuesday 2023 - Week 31",
    "section": "",
    "text": "Introduction\n\nThe #TidyTuesday weekly challenge is organised by the R4DS (R for Data Science) Online Learning Community.\nEvery tuesday throughout the year, participants work on a common dataset and share the plots they create.\nThe dataset for this challenge comes from Wikipedia articles.\n\n\n\nGetting the data\n\nFirst of all, let‚Äôs load the packages we‚Äôll be using :\n\n{tidyverse} to clean the data and create the plots\n{showtext} to change the fonts used\n{rgdal} and {rgeos} to plot the U.S. states as hexagons\n{ggtext} to add colours in the plot title\n\nIf you don‚Äôt have these packages installed, simply use the install.packages() function.\n\n# Load the packages\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(rgdal)\nlibrary(rgeos)\nlibrary(ggtext)\n\n\nWe also load the fonts we will use in the plots: Roboto Condensed for the text and Bangers for the title.\n\n# Import the fonts\nfont_add_google(\"Roboto Condensed\", \"Roboto Condensed\")\nfont_add_google(\"Bangers\", \"Bangers\")\nshowtext_auto()\n\n\nWe can now download the dataset :\n\n# Download the dataset\nstates &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-01/states.csv')\n\n\nWe also download the data to plot U.S. states as hexagons here. We save the GEO JSON file in a raw/ directory.\nWe then load the data:\n\n# Download the dataset\nus_hex &lt;- readOGR(\"raw/us_states_hexgrid.geojson\")\n\nFor a quick overview of the data, we use the glimpse() function from the {dplyr} package:\n\n# Explore the dataset\nglimpse(states)\n\nRows: 50\nColumns: 14\n$ state               &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"Calif‚Ä¶\n$ postal_abbreviation &lt;chr&gt; \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"F‚Ä¶\n$ capital_city        &lt;chr&gt; \"Montgomery\", \"Juneau\", \"Phoenix\", \"Little Rock\", ‚Ä¶\n$ largest_city        &lt;chr&gt; \"Huntsville\", \"Anchorage\", \"Phoenix\", \"Little Rock‚Ä¶\n$ admission           &lt;date&gt; 1819-12-14, 1959-01-03, 1912-02-14, 1836-06-15, 1‚Ä¶\n$ population_2020     &lt;dbl&gt; 5024279, 733391, 7151502, 3011524, 39538223, 57737‚Ä¶\n$ total_area_mi2      &lt;dbl&gt; 52420, 665384, 113990, 53179, 163695, 104094, 5543‚Ä¶\n$ total_area_km2      &lt;dbl&gt; 135767, 1723337, 295234, 137732, 423967, 269601, 1‚Ä¶\n$ land_area_mi2       &lt;dbl&gt; 50645, 570641, 113594, 52035, 155779, 103642, 4842‚Ä¶\n$ land_area_km2       &lt;dbl&gt; 131171, 1477953, 294207, 134771, 403466, 268431, 1‚Ä¶\n$ water_area_mi2      &lt;dbl&gt; 1775, 94743, 396, 1143, 7916, 452, 701, 540, 12133‚Ä¶\n$ water_area_km2      &lt;dbl&gt; 4597, 245384, 1026, 2961, 20501, 1170, 1816, 1399,‚Ä¶\n$ n_representatives   &lt;dbl&gt; 7, 1, 9, 4, 52, 8, 5, 1, 28, 14, 2, 2, 17, 9, 4, 4‚Ä¶\n$ demonym             &lt;chr&gt; \"Alabamian\", \"Alaskan\", \"Arizonan\", \"Arkansan\", \"C‚Ä¶\n\n\nThe dataset has 50 observations (rows) and 14 variables (columns).\nEach row represents one U.S. states.\nWe‚Äôre going to represent the ratios between land and water surfaces for each state.\n\n\n\nCleaning the data\n\nWe use the following code to calculate the land/water ratios:\n\n# Land to water area ratios\nland_to_water_ratios &lt;- states |&gt;\n  # calculate land/total and water/total area ratios\n  mutate(land_area_ratio = round(land_area_km2 / total_area_km2, 3),\n         water_area_ratio = round(1 - land_area_ratio, 3)) |&gt;\n  # select columns\n  select(id = postal_abbreviation, state, land_area_ratio, water_area_ratio)\n\n# View first lines of cleaned data\nhead(land_to_water_ratios)\n\n# A tibble: 6 √ó 4\n  id    state      land_area_ratio water_area_ratio\n  &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt;\n1 AL    Alabama              0.966            0.034\n2 AK    Alaska               0.858            0.142\n3 AZ    Arizona              0.997            0.003\n4 AR    Arkansas             0.979            0.021\n5 CA    California           0.952            0.048\n6 CO    Colorado             0.996            0.004\n\n\n\nWe calculate the coordinates for boundaries between land and water surfaces for each hexagon:\n\n# Prepare data to create hex map of land to water ratio per US state\nus_clean &lt;- us_hex |&gt;\n  # transform hex data into table\n  fortify(region = \"iso3166_2\") |&gt;\n  # transform into tibble format\n  as_tibble() |&gt;\n  # select columns\n  select(id, long, lat) |&gt;\n  # join land to water ratios values\n  left_join(land_to_water_ratios) |&gt;\n  # remove District of Columbia\n  filter(id != \"DC\") |&gt;\n  # add column with point order\n  mutate(pt_nb = rep(1:7, times = 50), .before = long) |&gt;\n  # group by state id\n  group_by(id) |&gt;\n  # calculate parameters for each state\n  mutate(\n    # total area for reactangle around hex\n    area_rect = (long[pt_nb == 3] - long[pt_nb == 5]) * (lat[pt_nb == 1] - lat[pt_nb == 4]),\n    # slope of upper hex triangle\n    slope = (lat[pt_nb == 6] - lat[pt_nb == 1]) / (long[pt_nb == 6] - long[pt_nb == 1]),\n    # y coordinate for horizontal border btwn land/water\n    split_y = ((land_area_ratio * area_rect) / (long[pt_nb == 2] - long[pt_nb == 6]) + lat[pt_nb == 4]),\n    # determine type of split : 1 if split line below upper triangle / 2 if not\n    split_type = case_when(split_y &lt;= lat[pt_nb == 2] ~ 1, TRUE ~ 2),\n    # calculate x coordinates for horizontal border btwn land/water\n    split_x1 = case_when(split_type == 1 ~ min(long),\n                         split_type == 2 ~ long[pt_nb == 6] + ((split_y - lat[pt_nb == 6]) / slope)),\n    split_x2 = case_when(split_type == 1 ~ max(long),\n                         split_type == 2 ~ long[pt_nb == 1] + (long[pt_nb == 1] - split_x1))\n    )\n\n# Subset us_clean data for type 1 split\nus_clean_type1 &lt;- us_clean |&gt;\n  # filter data\n  filter(split_type == 1) |&gt;\n  # create new columns to keep points needed for plot\n  mutate(pt1_x = long[pt_nb == 1], pt1_y = lat[pt_nb == 1],\n         pt2_x = long[pt_nb == 2], pt2_y = lat[pt_nb == 2],\n         pt3_x = unique(split_x2), pt3_y = unique(split_y),\n         pt4_x = unique(split_x1), pt4_y = unique(split_y),\n         pt5_x = long[pt_nb == 6], pt5_y = lat[pt_nb == 6],\n         pt6_x = pt1_x, pt6_y = pt1_y) |&gt;\n  # select columns\n  select(id, pt1_x:pt6_y) |&gt;\n  # ungroup data\n  ungroup() |&gt;\n  # pivot to long format\n  pivot_longer(cols = -id, names_to = \"pt\", values_to = \"value\") |&gt;\n  # separate \"pt\" column\n  separate(col = pt, into = c(\"pt_nb\", \"xy\"), sep = \"_\") |&gt;\n  # remove \"pt\" string from pt_nb column\n  mutate(pt_nb = str_remove_all(pt_nb, \"pt\")) |&gt;\n  # keep distinct rows\n  distinct() |&gt;\n  # pivot to wide format\n  pivot_wider(id_cols = id:pt_nb, names_from = \"xy\", values_from = \"value\")\n\n# Subset us_clean data for type 2 split\nus_clean_type2 &lt;- us_clean |&gt;\n  # filter data\n  filter(split_type == 2) |&gt;\n  # create new columns to keep points needed for plot\n  mutate(pt1_x = long[pt_nb == 1], pt1_y = lat[pt_nb == 1],\n         pt2_x = unique(split_x2), pt2_y = unique(split_y),\n         pt3_x = unique(split_x1), pt3_y = unique(split_y),\n         pt4_x = pt1_x, pt4_y = pt1_y) |&gt;\n  # select columns\n  select(id, pt1_x:pt4_y) |&gt;\n  # ungroup data\n  ungroup() |&gt;\n  # pivot to long format\n  pivot_longer(cols = -id, names_to = \"pt\", values_to = \"value\") |&gt;\n  # separate \"pt\" column\n  separate(col = pt, into = c(\"pt_nb\", \"xy\"), sep = \"_\") |&gt;\n  # remove \"pt\" string from pt_nb column\n  mutate(pt_nb = str_remove_all(pt_nb, \"pt\")) |&gt;\n  # keep distinct rows\n  distinct() |&gt;\n  # pivot to wide format\n  pivot_wider(id_cols = id:pt_nb, names_from = \"xy\", values_from = \"value\")\n\n\nWe calculate the coordinates of each hexagon‚Äôs centre to add text labels:\n\n# Calculate centres of polygons to plot state labels\ncentres &lt;- gCentroid(us_hex, byid = TRUE) |&gt;\n  as_tibble()\n\nlabels &lt;- us_hex@data$iso3166_2\n\nhex_labels &lt;- tibble(id = labels,\n                     centres) |&gt;\n  filter(id != \"DC\")\n\n# Clean global environment\nrm(centres, labels, land_to_water_ratios, states, us_hex)\n\n\n\n\nCreating the plot\n\n\np &lt;- ggplot() +\n  geom_polygon(data = us_clean, aes(x = long, y = lat, group = id),\n               colour = NA, fill = \"#48bf91\") +\n  geom_polygon(data = us_clean_type1, aes(x = x, y = y, group = id),\n               colour = NA, fill = \"#0076be\") +\n  geom_polygon(data = us_clean_type2, aes(x = x, y = y, group = id),\n               colour = NA, fill = \"#0076be\") +\n  geom_polygon(data = us_clean, aes(x = long, y = lat, group = id),\n               colour = \"white\", fill = NA, linewidth = 0.5) +\n  geom_text(data = hex_labels, aes(x = x, y = y, label = id),\n            family = \"Roboto Condensed\", colour = \"black\", size = 16) +\n  coord_map() +\n  labs(title = \"&lt;span style='color:#48bf91;'&gt;Land&lt;/span&gt; to &lt;span style='color:#0076be;'&gt;water&lt;/span&gt; surface ratios in the U.S.\",\n       caption = \"#TidyTuesday 2023 week 31 | Data from Wikipedia | Jonathan Kitt\") +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"black\", colour = NA),\n        plot.background = element_rect(fill = \"black\", colour = NA),\n        plot.title = element_markdown(family = \"Bangers\", size = 90,\n                                      hjust = 0.5, colour = \"white\",\n                                      margin = margin(t = 20)),\n        plot.caption = element_text(family = \"Roboto Condensed\", colour = \"white\", size = 30,\n                                    hjust = 0.5, \n                                    margin = margin(b = 5)))\n\nggsave(\"figs/tt_2023_w31_us.png\", p, dpi = 320, width = 12, height = 6)\n\n\nAnd here‚Äôs the result!"
  },
  {
    "objectID": "posts/2023-06-23-datardis/index.html",
    "href": "posts/2023-06-23-datardis/index.html",
    "title": "The {datardis} package",
    "section": "",
    "text": "The {datardis} package is available on CRAN:\n\ninstall.packages(\"datardis\")"
  },
  {
    "objectID": "posts/2023-06-23-datardis/index.html#accessing-the-datasets",
    "href": "posts/2023-06-23-datardis/index.html#accessing-the-datasets",
    "title": "The {datardis} package",
    "section": "Accessing the datasets",
    "text": "Accessing the datasets\n\nTo access the datasets, use the following commands:\n\n# Load the package\nlibrary(datardis)\n\n# List of Dr Who episodes\ndrwho_episodes\n\n# List of Dr Who directors\ndrwho_directors\n\n# List of Dr Who writers\ndrwho_writers\n\n# List of Torchwood episodes\ntorchwood_episodes\n\n# List of Torchwood directors\ntorchwood_directors\n\n# List of Torchwood writers\ntorchwood_writers"
  },
  {
    "objectID": "posts/2023-06-23-datardis/index.html#list-of-dr-who-episodes",
    "href": "posts/2023-06-23-datardis/index.html#list-of-dr-who-episodes",
    "title": "The {datardis} package",
    "section": "List of Dr Who episodes",
    "text": "List of Dr Who episodes\n\nTo view the dataset content, use the glimpse() function:\n\n# Load the tidyverse\nlibrary(tidyverse)\n\n# View the dataset content\nglimpse(drwho_episodes)\n\n\n\nRows: 175\nColumns: 12\n$ era             &lt;chr&gt; \"revived\", \"revived\", \"revived\", \"revived\", \"revived\",‚Ä¶\n$ season_number   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, ‚Ä¶\n$ serial_title    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA‚Ä¶\n$ story_number    &lt;chr&gt; \"157\", \"158\", \"159\", \"160a\", \"160b\", \"161\", \"162\", \"16‚Ä¶\n$ episode_number  &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, NA, 1, 2, 3‚Ä¶\n$ episode_title   &lt;chr&gt; \"Rose\", \"The End of the World\", \"The Unquiet Dead\", \"A‚Ä¶\n$ type            &lt;chr&gt; \"episode\", \"episode\", \"episode\", \"episode\", \"episode\",‚Ä¶\n$ first_aired     &lt;date&gt; 2005-03-26, 2005-04-02, 2005-04-09, 2005-04-16, 2005-‚Ä¶\n$ production_code &lt;chr&gt; \"1.1\", \"1.2\", \"1.3\", \"1.4\", \"1.5\", \"1.6\", \"1.7\", \"1.8\"‚Ä¶\n$ uk_viewers      &lt;dbl&gt; 10.81, 7.97, 8.86, 7.63, 7.98, 8.63, 8.01, 8.06, 7.11,‚Ä¶\n$ rating          &lt;dbl&gt; 76, 76, 80, 82, 81, 84, 81, 83, 84, 85, 82, 86, 89, 84‚Ä¶\n$ duration        &lt;dbl&gt; 45, 44, 44, 45, 42, 45, 44, 45, 45, 45, 45, 45, 45, 60‚Ä¶"
  },
  {
    "objectID": "posts/2023-06-23-datardis/index.html#who-wrote-the-most-dr-who-episodes",
    "href": "posts/2023-06-23-datardis/index.html#who-wrote-the-most-dr-who-episodes",
    "title": "The {datardis} package",
    "section": "Who wrote the most Dr Who episodes?",
    "text": "Who wrote the most Dr Who episodes?\n\nTo find out who wrote the most Dr Who episodes, use the following code:\n\ndrwho_writers |&gt; \n  count(writer, sort = TRUE) |&gt; \n  head(5)\n\n\n\n# A tibble: 5 √ó 2\n  writer               n\n  &lt;chr&gt;            &lt;int&gt;\n1 Steven Moffat       45\n2 Russell T Davies    31\n3 Chris Chibnall      29\n4 Mark Gatiss          9\n5 Toby Whithouse       7"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Hi, I am Jonathan üëã\n\nI currently work as a technician in the Genetics, Diversity and Ecophysiology of Cereals INRAE lab in Clermont-Ferrand, France.\n\n\nMy work focuses on the characterisation of bread wheat genetic diversity.\n\n\n\nWhat you‚Äôll find on this blog\n\n‚û°Ô∏è Posts about R\n\n\n‚û°Ô∏è Posts about data visualisation"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "jonathankitt",
    "section": "",
    "text": "Gradient descent\n\n\nOptimizing parameters\n\n\n\nR\n\n\nLinear Regression\n\n\nGradient descent\n\n\n\n\n\n\n\n\n\nFeb 19, 2025\n\n\nJonathan Kitt\n\n\n\n\n\n\n\n\n\n\n\n\nVend√©e Globe 2024\n\n\nMapping the skippers\n\n\n\nR\n\n\nVend√©e Globe\n\n\nMap\n\n\n\n\n\n\n\n\n\nNov 20, 2024\n\n\nJonathan Kitt\n\n\n\n\n\n\n\n\n\n\n\n\n{datardis} package v.0.0.5\n\n\nExplore the latest Dr Who episodes\n\n\n\nR\n\n\nPackage\n\n\nDr Who\n\n\n\n\n\n\n\n\n\nAug 22, 2024\n\n\nJonathan Kitt\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday 2023 - Week 37\n\n\nGlobal Human Day\n\n\n\nR\n\n\nTidyTuesday\n\n\ndatavis\n\n\nGlobal Human Day\n\n\n\n\n\n\n\n\n\nSep 12, 2023\n\n\nJonathan Kitt\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday 2023 - Week 35\n\n\nFair use\n\n\n\nR\n\n\nTidyTuesday\n\n\ndatavis\n\n\nFair use\n\n\n\n\n\n\n\n\n\nAug 29, 2023\n\n\nJonathan Kitt\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday 2023 - Week 32\n\n\nHot Ones\n\n\n\nR\n\n\nTidyTuesday\n\n\ndatavis\n\n\nHot Ones\n\n\n\n\n\n\n\n\n\nAug 10, 2023\n\n\nJonathan Kitt\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday 2023 - Week 31\n\n\nU.S. states\n\n\n\nR\n\n\nTidyTuesday\n\n\ndatavis\n\n\nU.S.\n\n\n\n\n\n\n\n\n\nAug 4, 2023\n\n\nJonathan Kitt\n\n\n\n\n\n\n\n\n\n\n\n\nTidyTuesday 2023 - Week 30\n\n\nCuring scurvy\n\n\n\nR\n\n\nTidyTuesday\n\n\ndatavis\n\n\nscurvy\n\n\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nJonathan Kitt\n\n\n\n\n\n\n\n\n\n\n\n\nThe {datardis} package\n\n\nExplore the Dr Who TV series\n\n\n\nR\n\n\npackage\n\n\nDr Who\n\n\n\n\n\n\n\n\n\nJun 23, 2023\n\n\nJonathan Kitt\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Links",
    "section": "",
    "text": "R bloggers"
  },
  {
    "objectID": "posts/2023-07-31-tt-scurvy/index.html",
    "href": "posts/2023-07-31-tt-scurvy/index.html",
    "title": "#TidyTuesday 2023 - Week 30",
    "section": "",
    "text": "The #TidyTuesday weekly challenge is organised by the R4DS (R for Data Science) Online Learning Community.\nEvery tuesday throughout the year, participants work on a common dataset and share the plots they create.\nThe dataset for this challenge comes from the {medicaldata} R package."
  },
  {
    "objectID": "posts/2023-07-31-tt-scurvy/index.html#text",
    "href": "posts/2023-07-31-tt-scurvy/index.html#text",
    "title": "#TidyTuesday 2023 - Week 30",
    "section": "Text",
    "text": "Text\n\nFirst we create a table for the text to be displayed:\n\n# Create table with text and x/y positions for plot\np_text &lt;- tibble(\n  x = 0,\n  y = c(6, 4:2, 0:-3, -5, -6),\n  text = c(\"In 1757, the cause of scurvy was unknown ...\",\n           \"Aboard HMS Salisbury, the ship's surgeon, James Lind,\",\n           \"tested 6 different treatments in 12 seamen with\",\n           \"symptomatic scurvy.\",\n           \"After six days of therapy, he noted the severity of several\",\n           \"symptoms, including rotting of the gums, skin sores,\",\n           \"weakness of the knees, and lassitude, using a scale ranging\",\n           \"from 0 (none) to 3 (severe).\",\n           \"The figure shows overall improvement of symptoms in the\",\n           \"treated seamen.\"\n           )\n  )\n\nWe then create a first plot with the text:\n\n# Create p0 plot with text\np0 &lt;- ggplot() +\n  geom_text(data = p_text,\n            aes(x = x, y = y, label = text),\n            family = \"Roboto Condensed\", colour = \"white\", hjust = 0, size = 18) +\n  xlim(0, 10) +\n  ylim(-10, 10) +\n  labs(title = \"Curing scurvy\") +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"#003049\", color  = \"#003049\"),\n        plot.background = element_rect(fill = \"#003049\", color  = \"#003049\"),\n        plot.title = element_text(family = \"Bangers\", colour = \"white\",\n                                  size = 100, hjust = 0.5, margin = margin(t = 20)))"
  },
  {
    "objectID": "posts/2023-07-31-tt-scurvy/index.html#improvement-scores",
    "href": "posts/2023-07-31-tt-scurvy/index.html#improvement-scores",
    "title": "#TidyTuesday 2023 - Week 30",
    "section": "Improvement scores",
    "text": "Improvement scores\n\nWe represent the overall improvement scores as percentages using coloured bars.\nFirst, we create data points to draw bars ranging from 0 to 100:\n\n# Create data points to draw bars from 0 to 100\np1_bars &lt;- overall_improvement |&gt;\n  # keep treatment column\n  select(treatment) |&gt;\n  # add a row id column named \"y\"\n  rowid_to_column(var = \"y\") |&gt;\n  # repeat each row 101 times (0 to 100)\n  slice(rep(1:n(), each = 101)) |&gt;\n  # add a column with positions to draw bars (for each of the 6 treatments)\n  mutate(x = rep(0:100, times = 6))\n\n\nThen we create data points to represent the actual improvement scores:\n\n# Create data points to draw bars for improvement scores\np1_values &lt;- overall_improvement |&gt;\n  # round improvement score %\n  mutate(improvement_score = round(improvement_score)) |&gt;\n  # select treatment + improvement score columns\n  select(treatment, improvement_score) |&gt;\n  # join p1_bars to get positions for bars from 0 to score\n  left_join(p1_bars) |&gt;\n  # extract max score for each treatment\n  mutate(max_score = max(improvement_score),\n         .by = treatment) |&gt;\n  # remove rows when x &gt; max_score\n  filter(x &lt;= max_score) |&gt;\n  # order columns\n  select(y, treatment, x)\n\n\nFinally, we create the plot:\n\n# Create data points to draw bars for improvement scores\np1 &lt;- ggplot() +\n  geom_segment(data = p1_bars,\n               aes(x = x, xend = x,\n                   y = y - 0.25, yend = y + 0.25,\n                   colour = x),\n               linewidth = 1, alpha = 0.4,\n               show.legend = FALSE) +\n  geom_segment(data = p1_values,\n               aes(x = x, xend = x,\n                   y = y - 0.25, yend = y + 0.25,\n                   colour = x),\n               linewidth = 1,\n               show.legend = FALSE) +\n  geom_text(data = p1_values |&gt; distinct(y, treatment),\n            aes(x = 0, y = y + 0.4, label = treatment),\n            size = 15, colour = \"white\", hjust = 0,\n            family = \"Roboto Condensed\") +\n  scale_colour_gradient2(low = \"#d62828\", mid = \"#f77f00\", high = \"#fcbf49\",\n                         midpoint = 50) +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"#003049\", color  = \"#003049\"),\n        plot.background = element_rect(fill = \"#003049\", color  = \"#003049\"))"
  },
  {
    "objectID": "posts/2023-07-31-tt-scurvy/index.html#assembling-the-plots",
    "href": "posts/2023-07-31-tt-scurvy/index.html#assembling-the-plots",
    "title": "#TidyTuesday 2023 - Week 30",
    "section": "Assembling the plots",
    "text": "Assembling the plots\n\nWe use the {patchwork} package to assemble the two plots, add some caption text, and export to .png format:\n\n# Assemble the two plots\np &lt;- p0 + p1 +\n  plot_annotation(\n    caption = \"#TidyTuesday 2023 week 30 | Data from {medicaldata} | Jonathan Kitt\",\n    theme = theme(\n      panel.background = element_rect(fill = \"#003049\", color  = \"#003049\"),\n      plot.background = element_rect(fill = \"#003049\", color  = \"#003049\"),\n      plot.caption = element_text(colour = \"white\", hjust = 0.5, size = 30,\n                                  family = \"Roboto Condensed\")\n      )\n    )\n\n# Export to png\nggsave(\"figs/tt_2023_w30_scurvy.png\", p, dpi = 320, width = 12, height = 6)\n\n\nAnd here‚Äôs the result!"
  },
  {
    "objectID": "posts/2023-08-10-tt-hot-ones/index.html",
    "href": "posts/2023-08-10-tt-hot-ones/index.html",
    "title": "#TidyTuesday 2023 - Week 32",
    "section": "",
    "text": "Introduction\n\nThe #TidyTuesday weekly challenge is organised by the R4DS (R for Data Science) Online Learning Community.\nEvery tuesday throughout the year, participants work on a common dataset and share the plots they create.\nThe dataset for this challenge comes from Wikipedia articles.\n\n\n\nGetting the data\n\nFirst of all, let‚Äôs load the packages we‚Äôll be using :\n\n{tidyverse} to clean the data and create the plots\n{showtext} to change the fonts used\n{patchwork} to combine the plots\n\nIf you don‚Äôt have these packages installed, simply use the install.packages() function.\n\n# Load the packages\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(patchwork)\n\n\nWe also load the fonts we will use in the plots: Bebas Neue for the text and Londrina Shadow for the title.\n\n# Import the fonts\nfont_add_google(\"Bebas Neue\", \"Bebas Neue\")\nfont_add_google(\"Londrina Shadow\", \"Londrina Shadow\")\nshowtext_auto()\n\n\nWe can now download the dataset :\n\n# Download the dataset\nsauces &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-08/sauces.csv')\n\n\nThe dataset has 210 observations (rows) and 4 variables (columns).\nEach row represents one sauce used in the show.\nThe 4 variables are:\n\nThe season number (1 to 21)\nThe sauce number (1 to 10, ordered from the least hot to the hottest)\nThe sauce name\nThe Scoville score (sauce rating in Scoville heat units)\n\n\n\n\nCleaning the data\n\nWe use the following code to clean the data:\n\n# Data cleaning and prep - Sauces per season ----\n\n# Scoville scale\nscoville_scale &lt;- tibble(\n  evaluation = c(\"01-Neutral\", \"02-Sweet\", \"03-Warm\", \"04-Spicy\",\n                 \"05-Hot\", \"06-Strong\", \"07-Raging\", \"08-Burning\",\n                 \"09-Torrid\", \"10-Volcanic\", \"11-Explosive\"))\n\n# Count number of sauces for each Scoville scale range per season\nsauces_count &lt;- sauces |&gt;\n  # Create categories for scoville scores\n  mutate(evaluation = case_when(scoville &lt; 100 ~ \"01-Neutral\",\n                                between(scoville, 100, 499) ~ \"02-Sweet\",\n                                between(scoville, 500, 999) ~ \"03-Warm\",\n                                between(scoville, 1000, 1499) ~ \"04-Spicy\",\n                                between(scoville, 1500, 2499) ~ \"05-Hot\",\n                                between(scoville, 2500, 4999) ~ \"06-Strong\",\n                                between(scoville, 5000, 14999) ~ \"07-Raging\",\n                                between(scoville, 15000, 29999) ~ \"08-Burning\",\n                                between(scoville, 30000, 49999) ~ \"09-Torrid\",\n                                between(scoville, 50000, 99999) ~ \"10-Volcanic\",\n                                scoville &gt;= 100000 ~ \"11-Explosive\")) |&gt;\n  # Count number of occurences per season and evaluation\n  count(season, evaluation) |&gt;\n  # Add full Scoville scale\n  right_join(scoville_scale) |&gt;\n  # Add non-existing scoville categories and fill empty cells with 0\n  complete(season, evaluation, fill = list(n = 0)) |&gt;\n  # Remove NAs\n  filter(!is.na(season))\n\n# p1 - Background\np1_bg &lt;- scoville_scale |&gt;\n  # Coordinates for rectangles\n  mutate(x1 = 0, x2 = 4, x3 = 46,\n         y1 = seq(0, 20, 2), y2 = seq(2, 22, 2)) |&gt;\n  # Split evaluation column into grade + evaluation\n  separate(evaluation, into = c(\"grade\", \"evaluation\"))\n\n# p1 - Grid\np1_grid &lt;- tibble(x0 = seq(4, 46, 2),\n                  x1 = x0,\n                  y0 = 0,\n                  y1 = 22)\n\n# p1 - Sauce count\np1_count &lt;- sauces_count |&gt;\n  # Split evaluation column into grade + evaluation\n  separate(evaluation, into = c(\"grade\", \"evaluation\")) |&gt;\n  # Add coordinates\n  mutate(y = rep(seq(1, 21, 2), times = 21)) |&gt;\n  # Order by grade and season\n  arrange(grade, season) |&gt;\n  # Add coordinates\n  mutate(x = rep(seq(5, 45, 2), times = 11)) |&gt;\n  # Remove empty rows\n  filter(n != 0)\n\n# p1 - Axis y text\np1_y_labels &lt;- tibble(x = -0.5,\n                      y = seq(2, 20, 2),\n                      score = c(\"100\", \"500\", \"1,000\", \"1,500\", \"2,500\", \"5,000\",\n                                \"15,000\", \"30,000\", \"50,000\", \"100,000\"))\n\n# Data cleaning and prep - Total score per season ----\n\n# p2 - scores\np2_scores &lt;- sauces |&gt;\n  # Calculate cumulative Scoville score for all 10 sauces per season\n  summarise(total = sum(scoville), .by = season) |&gt;\n  # Add coordinates + round to thousands of units\n  mutate(x = seq(5, 45, 2),\n         total_thsd = plyr::round_any(total, 1000) / 1000)\n\n# p2 - x axis labels\np2_x_labels &lt;- tibble(x = c(2, seq(5, 45, 2)),\n                      y = 3800,\n                      label = c(\"Season #\", 1:21))\n\n# p2 - text\np2_text &lt;- tibble(x = -0.95,\n                  y = c(2600, 2200, 1800, 1400),\n                  label = c(\"Overall Scoville\",\n                            \"heat score for all\",\n                            \"10 sauces (in 1,000s\",\n                            \"of units)\"))\n\n\n\n\nCreating the plot\n\nFirst we create a vector with custom colours:\n\ncustom_cols &lt;- c(\"Neutral\" = \"#86ff00\",\n                 \"Sweet\" = \"#bcff00\",\n                 \"Warm\" = \"#ddfa00\",\n                 \"Spicy\" = \"#edeb00\",\n                 \"Hot\" = \"#eecb00\",\n                 \"Strong\" = \"#ffbf03\",\n                 \"Raging\" = \"#ff9000\",\n                 \"Burning\" = \"#ff6100\",\n                 \"Torrid\" = \"#fe3000\",\n                 \"Volcanic\" = \"#ee0000\",\n                 \"Explosive\" = \"#790200\")\n\n\nWe then create the first plot:\n\n# Create plot - p1 ----\n\np1 &lt;- ggplot() +\n  geom_rect(data = p1_bg,\n            aes(xmin = x1, xmax = x2, ymin = y1, ymax = y2,\n                fill = evaluation),\n            show.legend = FALSE) +\n  geom_rect(data = p1_bg,\n            aes(xmin = x2, xmax = x3, ymin = y1, ymax = y2,\n                fill = evaluation),\n            alpha = 0.5, show.legend = FALSE) +\n  geom_segment(data = p1_grid,\n               aes(x = x0, xend = x1, y = y0, yend = y1)) +\n  geom_text(data = p1_bg,\n            aes(x = 2, y = y1 + 1, label = evaluation),\n            colour = \"black\", family = \"Bebas Neue\", size = 14) +\n  geom_text(data = p1_count,\n            aes(x = x, y = y, label = n),\n            colour = \"white\", family = \"Bebas Neue\", size = 14) +\n  geom_text(data = p1_y_labels,\n            aes(x = x, y = y, label = score),\n            size = 12, hjust = 1, colour = \"white\") +\n  geom_text(aes(x = 2, y = 23.5, label = \"Scoville scale\"),\n            family = \"Bebas Neue\", size = 16, hjust = 0.5, colour = \"white\") +\n  scale_fill_manual(values = custom_cols) +\n  xlim(-1, 46) +\n  labs(title = \"Number of sauces used\") +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"black\"),\n        plot.background = element_rect(fill = \"black\"),\n        plot.title = element_text(family = \"Bebas Neue\", colour = \"white\",\n                                  size = 60, hjust = 0.5, margin = margin(t = 20)))\n\n\nWe now create the second plot:\n\n# Create plot - p2 ----\n\np2 &lt;- ggplot() +\n  geom_rect(data = p2_scores,\n             aes(xmin = x - 0.85, xmax = x + 0.85,\n                 ymin = 0, ymax = total_thsd),\n            fill = \"#edeb00\") +\n  geom_text(data = p2_scores,\n            aes(x = x, y = total_thsd - 160, label = total_thsd),\n            family = \"Bebas Neue\", colour = \"black\", size = 18) +\n  geom_text(data = p2_x_labels,\n            aes(x = x, y = y, label = label),\n            family = \"Bebas Neue\", colour = \"white\", size = 18) +\n  geom_text(data = p2_text,\n            aes(x = x, y = y, label = label),\n            family = \"Bebas Neue\", colour = \"white\", size = 20,\n            hjust = 0) +\n  xlim(-1, 46) +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"black\"),\n        plot.background = element_rect(fill = \"black\"))\n\n\nWe use the {patchwork} package to assemble the plots:\n\n# Assemble plots\np &lt;- p1 / p2 +\n  plot_annotation(title = \"Hot Ones\",\n                  caption = \"#TidyTuesday 2023 week 32 | Data from Wikipedia | Jonathan Kitt\",\n                  theme = theme(panel.background = element_rect(fill = \"black\", colour = \"black\"),\n                                plot.background = element_rect(fill = \"black\", colour = \"black\"),\n                                plot.title = element_text(family = \"Londrina Shadow\",\n                                                          size = 125, hjust = 0.5,\n                                                          colour = \"#edeb00\",\n                                                          margin = margin(t = 10)),\n                                plot.caption = element_text(size = 20, colour = \"white\", hjust = 0.5)))\n\n# Export plot\n\nggsave(\"figs/tt_2023_w32_hot_ones.png\", p, dpi = 320, width = 12, height = 6)\n\n\nAnd here‚Äôs the result!"
  },
  {
    "objectID": "posts/2023-09-12-tt-global-human-day/index.html",
    "href": "posts/2023-09-12-tt-global-human-day/index.html",
    "title": "#TidyTuesday 2023 - Week 37",
    "section": "",
    "text": "Introduction\n\nThe #TidyTuesday weekly challenge is organised by the R4DS (R for Data Science) Online Learning Community.\nEvery tuesday throughout the year, participants work on a common dataset and share the plots they create.\nThe dataset for this challenge comes from the Human Chronome Project.\n\n\n\nGetting the data\n\nFirst of all, let‚Äôs load the packages we‚Äôll be using :\n\n{tidyverse} to clean the data and create the plots\n{showtext} to change the fonts used\n{patchwork} to assemble the plots\n\nIf you don‚Äôt have these packages installed, simply use the install.packages() function.\n\n# üì¶ Load packages ----\n\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(patchwork)\n\n\nWe also load the fonts we will use in the plots.\n\n# üî§ Import fonts ----\n\nfont_add_google(\"Roboto Condensed\", \"Roboto Condensed\")\nshowtext_auto()\n\n\nWe can now download the dataset :\n\n# ‚¨áÔ∏è Import the dataset ----\nall_countries &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-09-12/all_countries.csv\")\nglobal_human_day &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-09-12/global_human_day.csv\")\n\n\n\n\nCleaning the data\n\nWe use the following code to clean the data:\n\n# üßπ  Clean the data ----\n\ncategories &lt;- all_countries |&gt;\n  # extract unique values\n  distinct(Category, Subcategory)\n\nd &lt;- global_human_day |&gt;\n  # join the categories\n  left_join(categories) |&gt;\n  # select columns\n  select(Category, hoursPerDay) |&gt;\n  # add hours per category\n  summarise(total = sum(hoursPerDay), .by = Category) |&gt;\n  # arrange by decreasing amount of time\n  arrange(-total) |&gt;\n  # split the total column into two values\n  separate(col = total, into = c(\"h\", \"m\"), remove = F) |&gt;\n  # transform the trailing hours value into minutes\n  mutate(m = round(as.numeric(paste0(\"0.\", m)) * 60),\n         h = as.numeric(h)) |&gt;\n  # create labels for plots\n  mutate(duration = case_when(h == 0 ~ paste0(m, \"m\"),\n                              TRUE ~ paste0(h, \"h \", m, \"m\"))) |&gt;\n  # select columns\n  select(Category, total, duration)\n\n\n\n\nCreating the plot\n\nFirst we create a custom function to generate one plot per category :\n\nplot_hm &lt;- function(data, row) {\n  ggplot() +\n    geom_rect(aes(xmin = 3, xmax = 4,\n                  ymin = 0, ymax = 24),\n              colour = \"#7e38b7\", fill = \"#7e38b7\") +\n    geom_rect(data = slice(data, row),\n              aes(xmin = 3, xmax = 4,\n                  ymin = 0, ymax = total),\n              colour = \"#9c89ff\", fill = \"#9c89ff\") +\n    coord_polar(theta = \"y\") +\n    xlim(c(0.05, 4)) +\n    labs(title = d$Category[row]) +\n    annotate(\"text\", x = 0.05, y = 0,\n             label = d$duration[row],\n             family = \"Roboto Condensed\",\n             colour = \"#c4feff\",\n             size = 25) +\n    theme_void() +\n    theme(panel.background = element_rect(fill = \"#541675\",\n                                          colour = NA),\n          plot.background = element_rect(fill = \"#541675\",\n                                         colour = NA),\n          plot.title = element_text(family = \"Roboto Condensed\",\n                                    colour = \"#c4feff\", size = 40,\n                                    hjust = 0.5,\n                                    margin = margin(b = -10)))\n}\n\n\nWe use the following code to create and assemble the plots and export the final figure :\n\n# Create the plots\np1 &lt;- plot_hm(d, 1)\np2 &lt;- plot_hm(d, 2)\np3 &lt;- plot_hm(d, 3)\np4 &lt;- plot_hm(d, 4)\np5 &lt;- plot_hm(d, 5)\np6 &lt;- plot_hm(d, 6)\np7 &lt;- plot_hm(d, 7)\np8 &lt;- plot_hm(d, 8)\n\n# Assemble the plots\np &lt;- (p1 + p2 + p3 + p4 + p5 + p6 + p7 + p8) +\n  plot_layout(ncol = 4) +\n  plot_annotation(title = \"How humans spend their day time\",\n                  caption = \"#TidyTuesday 2023 week 37 | Data from the Human Chronome Project | Jonathan Kitt\",\n                  theme = theme(panel.background = element_rect(fill = \"#541675\", colour = NA),\n                                plot.background = element_rect(fill = \"#541675\", colour = NA),\n                                plot.title = element_text(family = \"Roboto Condensed\",\n                                                            colour = \"#c4feff\", size = 100,\n                                                            hjust = 0.5, margin = margin(t = 5, b = 25)),\n                                plot.caption = element_text(family = \"Roboto Condensed\",\n                                                            colour = \"white\", size = 30, hjust = 0.5)))\n\n# Export the plot\nggsave(\"figs/tt_2023_w37_global_human_day.png\", p, dpi = 320, width = 12, height = 6)\n\n\nWe now create the second plot:\n\nAnd here‚Äôs the result!"
  },
  {
    "objectID": "posts/2024-11-20-vendee-globe/index.html",
    "href": "posts/2024-11-20-vendee-globe/index.html",
    "title": "Vend√©e Globe 2024",
    "section": "",
    "text": "The Vend√©e Globe 2024 is well under way!\n\nI wanted to see if I could try a map of the skippers with R.\nFollow this tutorial if you‚Äôd like to try it for yourself!"
  },
  {
    "objectID": "posts/2024-11-20-vendee-globe/index.html#world-map",
    "href": "posts/2024-11-20-vendee-globe/index.html#world-map",
    "title": "Vend√©e Globe 2024",
    "section": "World map",
    "text": "World map\n\nFirst we get the data for the world map:\n\nworld &lt;- map_data(\"world\")"
  },
  {
    "objectID": "posts/2024-11-20-vendee-globe/index.html#skippers",
    "href": "posts/2024-11-20-vendee-globe/index.html#skippers",
    "title": "Vend√©e Globe 2024",
    "section": "Skippers",
    "text": "Skippers\n\nWe then create a simple map with the latest standings:\n\nggplot() +\n  geom_polygon(data = world, aes(x = long, y = lat, group = group),\n               fill = \"#afcfdf\") +\n  geom_point(data = filter(df, Date == 20241120, Time == \"060000\"),\n             aes(x = lon, y = lat),\n             col = \"white\", size = 0.8) +\n  coord_fixed(ratio = 1.3, xlim = c(-35, 0), ylim = c(5, 30)) +\n  labs(title = \"Vend√©e Globe 2024\",\n       subtitle = \"2024-11-20 6:00\") +\n  theme_void() +\n  theme(panel.background = element_rect(colour = \"#485fb0\",\n                                        fill = \"#485fb0\"),\n        plot.background = element_rect(colour = \"#485fb0\",\n                                        fill = \"#485fb0\"),\n        # plot.margin = margin(t = -50, r = -150),\n        plot.title = element_text(colour = \"white\",\n                                  family = \"Roboto Condensed\",\n                                  size = 20, hjust = 0.5),\n        plot.subtitle = element_text(colour = \"white\",\n                                     family = \"Roboto Condensed\",\n                                     size = 15, hjust = 0.5))"
  },
  {
    "objectID": "posts/2024-11-20-vendee-globe/index.html#save-map",
    "href": "posts/2024-11-20-vendee-globe/index.html#save-map",
    "title": "Vend√©e Globe 2024",
    "section": "Save map",
    "text": "Save map\n\nWe now save the map :\n\nggsave(\"20241120_060000.png\", p, dpi = 320, width = 6, height = 6)\n\n\nAnd here‚Äôs the result:"
  }
]