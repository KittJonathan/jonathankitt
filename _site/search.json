[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "jonathankitt",
    "section": "",
    "text": "TidyTuesday 2023 - Week 35\n\n\nFair use\n\n\n\n\nR\n\n\nTidyTuesday\n\n\ndatavis\n\n\nFair use\n\n\n\n\n\n\n\n\n\n\n\nAug 29, 2023\n\n\nJonathan Kitt\n\n\n\n\n\n\n  \n\n\n\n\nTidyTuesday 2023 - Week 32\n\n\nHot Ones\n\n\n\n\nR\n\n\nTidyTuesday\n\n\ndatavis\n\n\nHot Ones\n\n\n\n\n\n\n\n\n\n\n\nAug 10, 2023\n\n\nJonathan Kitt\n\n\n\n\n\n\n  \n\n\n\n\nTidyTuesday 2023 - Week 31\n\n\nU.S. states\n\n\n\n\nR\n\n\nTidyTuesday\n\n\ndatavis\n\n\nU.S.\n\n\n\n\n\n\n\n\n\n\n\nAug 4, 2023\n\n\nJonathan Kitt\n\n\n\n\n\n\n  \n\n\n\n\nTidyTuesday 2023 - Week 30\n\n\nCuring scurvy\n\n\n\n\nR\n\n\nTidyTuesday\n\n\ndatavis\n\n\nscurvy\n\n\n\n\n\n\n\n\n\n\n\nJul 31, 2023\n\n\nJonathan Kitt\n\n\n\n\n\n\n  \n\n\n\n\nThe {datardis} package\n\n\nExplore the Dr Who TV series\n\n\n\n\nR\n\n\npackage\n\n\nDr Who\n\n\n\n\n\n\n\n\n\n\n\nJun 23, 2023\n\n\nJonathan Kitt\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome!",
    "section": "",
    "text": "Hi, I am Jonathan üëã\n\nI currently work as a technician in the Genetics, Diversity and Ecophysiology of Cereals INRAE lab in Clermont-Ferrand, France.\n\n\nMy work focuses on the characterisation of bread wheat genetic diversity.\n\n\n\nWhat you‚Äôll find on this blog\n\n‚û°Ô∏è Posts about R\n\n\n‚û°Ô∏è Posts about data visualisation"
  },
  {
    "objectID": "links.html",
    "href": "links.html",
    "title": "Links",
    "section": "",
    "text": "Books"
  },
  {
    "objectID": "posts/2023-06-23-datardis/index.html",
    "href": "posts/2023-06-23-datardis/index.html",
    "title": "The {datardis} package",
    "section": "",
    "text": "The {datardis} package is available on CRAN:\n\ninstall.packages(\"datardis\")"
  },
  {
    "objectID": "posts/2023-06-23-datardis/index.html#accessing-the-datasets",
    "href": "posts/2023-06-23-datardis/index.html#accessing-the-datasets",
    "title": "The {datardis} package",
    "section": "Accessing the datasets",
    "text": "Accessing the datasets\n\nTo access the datasets, use the following commands:\n\n# Load the package\nlibrary(datardis)\n\n# List of Dr Who episodes\ndrwho_episodes\n\n# List of Dr Who directors\ndrwho_directors\n\n# List of Dr Who writers\ndrwho_writers\n\n# List of Torchwood episodes\ntorchwood_episodes\n\n# List of Torchwood directors\ntorchwood_directors\n\n# List of Torchwood writers\ntorchwood_writers"
  },
  {
    "objectID": "posts/2023-06-23-datardis/index.html#list-of-dr-who-episodes",
    "href": "posts/2023-06-23-datardis/index.html#list-of-dr-who-episodes",
    "title": "The {datardis} package",
    "section": "List of Dr Who episodes",
    "text": "List of Dr Who episodes\n\nTo view the dataset content, use the glimpse() function:\n\n# Load the tidyverse\nlibrary(tidyverse)\n\n# View the dataset content\nglimpse(drwho_episodes)\n\n\n\nRows: 175\nColumns: 12\n$ era             &lt;chr&gt; \"revived\", \"revived\", \"revived\", \"revived\", \"revived\",‚Ä¶\n$ season_number   &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, ‚Ä¶\n$ serial_title    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA‚Ä¶\n$ story_number    &lt;chr&gt; \"157\", \"158\", \"159\", \"160a\", \"160b\", \"161\", \"162\", \"16‚Ä¶\n$ episode_number  &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, NA, 1, 2, 3‚Ä¶\n$ episode_title   &lt;chr&gt; \"Rose\", \"The End of the World\", \"The Unquiet Dead\", \"A‚Ä¶\n$ type            &lt;chr&gt; \"episode\", \"episode\", \"episode\", \"episode\", \"episode\",‚Ä¶\n$ first_aired     &lt;date&gt; 2005-03-26, 2005-04-02, 2005-04-09, 2005-04-16, 2005-‚Ä¶\n$ production_code &lt;chr&gt; \"1.1\", \"1.2\", \"1.3\", \"1.4\", \"1.5\", \"1.6\", \"1.7\", \"1.8\"‚Ä¶\n$ uk_viewers      &lt;dbl&gt; 10.81, 7.97, 8.86, 7.63, 7.98, 8.63, 8.01, 8.06, 7.11,‚Ä¶\n$ rating          &lt;dbl&gt; 76, 76, 80, 82, 81, 84, 81, 83, 84, 85, 82, 86, 89, 84‚Ä¶\n$ duration        &lt;dbl&gt; 45, 44, 44, 45, 42, 45, 44, 45, 45, 45, 45, 45, 45, 60‚Ä¶"
  },
  {
    "objectID": "posts/2023-06-23-datardis/index.html#who-wrote-the-most-dr-who-episodes",
    "href": "posts/2023-06-23-datardis/index.html#who-wrote-the-most-dr-who-episodes",
    "title": "The {datardis} package",
    "section": "Who wrote the most Dr Who episodes?",
    "text": "Who wrote the most Dr Who episodes?\n\nTo find out who wrote the most Dr Who episodes, use the following code:\n\ndrwho_writers |&gt; \n  count(writer, sort = TRUE) |&gt; \n  head(5)\n\n\n\n# A tibble: 5 √ó 2\n  writer               n\n  &lt;chr&gt;            &lt;int&gt;\n1 Steven Moffat       45\n2 Russell T Davies    31\n3 Chris Chibnall      29\n4 Mark Gatiss          9\n5 Toby Whithouse       7"
  },
  {
    "objectID": "posts/2023-07-31-tt-scurvy/index.html",
    "href": "posts/2023-07-31-tt-scurvy/index.html",
    "title": "#TidyTuesday 2023 - Week 30",
    "section": "",
    "text": "The #TidyTuesday weekly challenge is organised by the R4DS (R for Data Science) Online Learning Community.\nEvery tuesday throughout the year, participants work on a common dataset and share the plots they create.\nThe dataset for this challenge comes from the {medicaldata} R package."
  },
  {
    "objectID": "posts/2023-07-31-tt-scurvy/index.html#text",
    "href": "posts/2023-07-31-tt-scurvy/index.html#text",
    "title": "#TidyTuesday 2023 - Week 30",
    "section": "Text",
    "text": "Text\n\nFirst we create a table for the text to be displayed:\n\n# Create table with text and x/y positions for plot\np_text &lt;- tibble(\n  x = 0,\n  y = c(6, 4:2, 0:-3, -5, -6),\n  text = c(\"In 1757, the cause of scurvy was unknown ...\",\n           \"Aboard HMS Salisbury, the ship's surgeon, James Lind,\",\n           \"tested 6 different treatments in 12 seamen with\",\n           \"symptomatic scurvy.\",\n           \"After six days of therapy, he noted the severity of several\",\n           \"symptoms, including rotting of the gums, skin sores,\",\n           \"weakness of the knees, and lassitude, using a scale ranging\",\n           \"from 0 (none) to 3 (severe).\",\n           \"The figure shows overall improvement of symptoms in the\",\n           \"treated seamen.\"\n           )\n  )\n\nWe then create a first plot with the text:\n\n# Create p0 plot with text\np0 &lt;- ggplot() +\n  geom_text(data = p_text,\n            aes(x = x, y = y, label = text),\n            family = \"Roboto Condensed\", colour = \"white\", hjust = 0, size = 18) +\n  xlim(0, 10) +\n  ylim(-10, 10) +\n  labs(title = \"Curing scurvy\") +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"#003049\", color  = \"#003049\"),\n        plot.background = element_rect(fill = \"#003049\", color  = \"#003049\"),\n        plot.title = element_text(family = \"Bangers\", colour = \"white\",\n                                  size = 100, hjust = 0.5, margin = margin(t = 20)))"
  },
  {
    "objectID": "posts/2023-07-31-tt-scurvy/index.html#improvement-scores",
    "href": "posts/2023-07-31-tt-scurvy/index.html#improvement-scores",
    "title": "#TidyTuesday 2023 - Week 30",
    "section": "Improvement scores",
    "text": "Improvement scores\n\nWe represent the overall improvement scores as percentages using coloured bars.\nFirst, we create data points to draw bars ranging from 0 to 100:\n\n# Create data points to draw bars from 0 to 100\np1_bars &lt;- overall_improvement |&gt;\n  # keep treatment column\n  select(treatment) |&gt;\n  # add a row id column named \"y\"\n  rowid_to_column(var = \"y\") |&gt;\n  # repeat each row 101 times (0 to 100)\n  slice(rep(1:n(), each = 101)) |&gt;\n  # add a column with positions to draw bars (for each of the 6 treatments)\n  mutate(x = rep(0:100, times = 6))\n\n\nThen we create data points to represent the actual improvement scores:\n\n# Create data points to draw bars for improvement scores\np1_values &lt;- overall_improvement |&gt;\n  # round improvement score %\n  mutate(improvement_score = round(improvement_score)) |&gt;\n  # select treatment + improvement score columns\n  select(treatment, improvement_score) |&gt;\n  # join p1_bars to get positions for bars from 0 to score\n  left_join(p1_bars) |&gt;\n  # extract max score for each treatment\n  mutate(max_score = max(improvement_score),\n         .by = treatment) |&gt;\n  # remove rows when x &gt; max_score\n  filter(x &lt;= max_score) |&gt;\n  # order columns\n  select(y, treatment, x)\n\n\nFinally, we create the plot:\n\n# Create data points to draw bars for improvement scores\np1 &lt;- ggplot() +\n  geom_segment(data = p1_bars,\n               aes(x = x, xend = x,\n                   y = y - 0.25, yend = y + 0.25,\n                   colour = x),\n               linewidth = 1, alpha = 0.4,\n               show.legend = FALSE) +\n  geom_segment(data = p1_values,\n               aes(x = x, xend = x,\n                   y = y - 0.25, yend = y + 0.25,\n                   colour = x),\n               linewidth = 1,\n               show.legend = FALSE) +\n  geom_text(data = p1_values |&gt; distinct(y, treatment),\n            aes(x = 0, y = y + 0.4, label = treatment),\n            size = 15, colour = \"white\", hjust = 0,\n            family = \"Roboto Condensed\") +\n  scale_colour_gradient2(low = \"#d62828\", mid = \"#f77f00\", high = \"#fcbf49\",\n                         midpoint = 50) +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"#003049\", color  = \"#003049\"),\n        plot.background = element_rect(fill = \"#003049\", color  = \"#003049\"))"
  },
  {
    "objectID": "posts/2023-07-31-tt-scurvy/index.html#assembling-the-plots",
    "href": "posts/2023-07-31-tt-scurvy/index.html#assembling-the-plots",
    "title": "#TidyTuesday 2023 - Week 30",
    "section": "Assembling the plots",
    "text": "Assembling the plots\n\nWe use the {patchwork} package to assemble the two plots, add some caption text, and export to .png format:\n\n# Assemble the two plots\np &lt;- p0 + p1 +\n  plot_annotation(\n    caption = \"#TidyTuesday 2023 week 30 | Data from {medicaldata} | Jonathan Kitt\",\n    theme = theme(\n      panel.background = element_rect(fill = \"#003049\", color  = \"#003049\"),\n      plot.background = element_rect(fill = \"#003049\", color  = \"#003049\"),\n      plot.caption = element_text(colour = \"white\", hjust = 0.5, size = 30,\n                                  family = \"Roboto Condensed\")\n      )\n    )\n\n# Export to png\nggsave(\"figs/tt_2023_w30_scurvy.png\", p, dpi = 320, width = 12, height = 6)\n\n\nAnd here‚Äôs the result!"
  },
  {
    "objectID": "posts/2023-08-04-tt-us/index.html",
    "href": "posts/2023-08-04-tt-us/index.html",
    "title": "#TidyTuesday 2023 - Week 31",
    "section": "",
    "text": "Introduction\n\nThe #TidyTuesday weekly challenge is organised by the R4DS (R for Data Science) Online Learning Community.\nEvery tuesday throughout the year, participants work on a common dataset and share the plots they create.\nThe dataset for this challenge comes from Wikipedia articles.\n\n\n\nGetting the data\n\nFirst of all, let‚Äôs load the packages we‚Äôll be using :\n\n{tidyverse} to clean the data and create the plots\n{showtext} to change the fonts used\n{rgdal} and {rgeos} to plot the U.S. states as hexagons\n{ggtext} to add colours in the plot title\n\nIf you don‚Äôt have these packages installed, simply use the install.packages() function.\n\n# Load the packages\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(rgdal)\nlibrary(rgeos)\nlibrary(ggtext)\n\n\nWe also load the fonts we will use in the plots: Roboto Condensed for the text and Bangers for the title.\n\n# Import the fonts\nfont_add_google(\"Roboto Condensed\", \"Roboto Condensed\")\nfont_add_google(\"Bangers\", \"Bangers\")\nshowtext_auto()\n\n\nWe can now download the dataset :\n\n# Download the dataset\nstates &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-01/states.csv')\n\n\nWe also download the data to plot U.S. states as hexagons here. We save the GEO JSON file in a raw/ directory.\nWe then load the data:\n\n# Download the dataset\nus_hex &lt;- readOGR(\"raw/us_states_hexgrid.geojson\")\n\nFor a quick overview of the data, we use the glimpse() function from the {dplyr} package:\n\n# Explore the dataset\nglimpse(states)\n\nRows: 50\nColumns: 14\n$ state               &lt;chr&gt; \"Alabama\", \"Alaska\", \"Arizona\", \"Arkansas\", \"Calif‚Ä¶\n$ postal_abbreviation &lt;chr&gt; \"AL\", \"AK\", \"AZ\", \"AR\", \"CA\", \"CO\", \"CT\", \"DE\", \"F‚Ä¶\n$ capital_city        &lt;chr&gt; \"Montgomery\", \"Juneau\", \"Phoenix\", \"Little Rock\", ‚Ä¶\n$ largest_city        &lt;chr&gt; \"Huntsville\", \"Anchorage\", \"Phoenix\", \"Little Rock‚Ä¶\n$ admission           &lt;date&gt; 1819-12-14, 1959-01-03, 1912-02-14, 1836-06-15, 1‚Ä¶\n$ population_2020     &lt;dbl&gt; 5024279, 733391, 7151502, 3011524, 39538223, 57737‚Ä¶\n$ total_area_mi2      &lt;dbl&gt; 52420, 665384, 113990, 53179, 163695, 104094, 5543‚Ä¶\n$ total_area_km2      &lt;dbl&gt; 135767, 1723337, 295234, 137732, 423967, 269601, 1‚Ä¶\n$ land_area_mi2       &lt;dbl&gt; 50645, 570641, 113594, 52035, 155779, 103642, 4842‚Ä¶\n$ land_area_km2       &lt;dbl&gt; 131171, 1477953, 294207, 134771, 403466, 268431, 1‚Ä¶\n$ water_area_mi2      &lt;dbl&gt; 1775, 94743, 396, 1143, 7916, 452, 701, 540, 12133‚Ä¶\n$ water_area_km2      &lt;dbl&gt; 4597, 245384, 1026, 2961, 20501, 1170, 1816, 1399,‚Ä¶\n$ n_representatives   &lt;dbl&gt; 7, 1, 9, 4, 52, 8, 5, 1, 28, 14, 2, 2, 17, 9, 4, 4‚Ä¶\n$ demonym             &lt;chr&gt; \"Alabamian\", \"Alaskan\", \"Arizonan\", \"Arkansan\", \"C‚Ä¶\n\n\nThe dataset has 50 observations (rows) and 14 variables (columns).\nEach row represents one U.S. states.\nWe‚Äôre going to represent the ratios between land and water surfaces for each state.\n\n\n\nCleaning the data\n\nWe use the following code to calculate the land/water ratios:\n\n# Land to water area ratios\nland_to_water_ratios &lt;- states |&gt;\n  # calculate land/total and water/total area ratios\n  mutate(land_area_ratio = round(land_area_km2 / total_area_km2, 3),\n         water_area_ratio = round(1 - land_area_ratio, 3)) |&gt;\n  # select columns\n  select(id = postal_abbreviation, state, land_area_ratio, water_area_ratio)\n\n# View first lines of cleaned data\nhead(land_to_water_ratios)\n\n# A tibble: 6 √ó 4\n  id    state      land_area_ratio water_area_ratio\n  &lt;chr&gt; &lt;chr&gt;                &lt;dbl&gt;            &lt;dbl&gt;\n1 AL    Alabama              0.966            0.034\n2 AK    Alaska               0.858            0.142\n3 AZ    Arizona              0.997            0.003\n4 AR    Arkansas             0.979            0.021\n5 CA    California           0.952            0.048\n6 CO    Colorado             0.996            0.004\n\n\n\nWe calculate the coordinates for boundaries between land and water surfaces for each hexagon:\n\n# Prepare data to create hex map of land to water ratio per US state\nus_clean &lt;- us_hex |&gt;\n  # transform hex data into table\n  fortify(region = \"iso3166_2\") |&gt;\n  # transform into tibble format\n  as_tibble() |&gt;\n  # select columns\n  select(id, long, lat) |&gt;\n  # join land to water ratios values\n  left_join(land_to_water_ratios) |&gt;\n  # remove District of Columbia\n  filter(id != \"DC\") |&gt;\n  # add column with point order\n  mutate(pt_nb = rep(1:7, times = 50), .before = long) |&gt;\n  # group by state id\n  group_by(id) |&gt;\n  # calculate parameters for each state\n  mutate(\n    # total area for reactangle around hex\n    area_rect = (long[pt_nb == 3] - long[pt_nb == 5]) * (lat[pt_nb == 1] - lat[pt_nb == 4]),\n    # slope of upper hex triangle\n    slope = (lat[pt_nb == 6] - lat[pt_nb == 1]) / (long[pt_nb == 6] - long[pt_nb == 1]),\n    # y coordinate for horizontal border btwn land/water\n    split_y = ((land_area_ratio * area_rect) / (long[pt_nb == 2] - long[pt_nb == 6]) + lat[pt_nb == 4]),\n    # determine type of split : 1 if split line below upper triangle / 2 if not\n    split_type = case_when(split_y &lt;= lat[pt_nb == 2] ~ 1, TRUE ~ 2),\n    # calculate x coordinates for horizontal border btwn land/water\n    split_x1 = case_when(split_type == 1 ~ min(long),\n                         split_type == 2 ~ long[pt_nb == 6] + ((split_y - lat[pt_nb == 6]) / slope)),\n    split_x2 = case_when(split_type == 1 ~ max(long),\n                         split_type == 2 ~ long[pt_nb == 1] + (long[pt_nb == 1] - split_x1))\n    )\n\n# Subset us_clean data for type 1 split\nus_clean_type1 &lt;- us_clean |&gt;\n  # filter data\n  filter(split_type == 1) |&gt;\n  # create new columns to keep points needed for plot\n  mutate(pt1_x = long[pt_nb == 1], pt1_y = lat[pt_nb == 1],\n         pt2_x = long[pt_nb == 2], pt2_y = lat[pt_nb == 2],\n         pt3_x = unique(split_x2), pt3_y = unique(split_y),\n         pt4_x = unique(split_x1), pt4_y = unique(split_y),\n         pt5_x = long[pt_nb == 6], pt5_y = lat[pt_nb == 6],\n         pt6_x = pt1_x, pt6_y = pt1_y) |&gt;\n  # select columns\n  select(id, pt1_x:pt6_y) |&gt;\n  # ungroup data\n  ungroup() |&gt;\n  # pivot to long format\n  pivot_longer(cols = -id, names_to = \"pt\", values_to = \"value\") |&gt;\n  # separate \"pt\" column\n  separate(col = pt, into = c(\"pt_nb\", \"xy\"), sep = \"_\") |&gt;\n  # remove \"pt\" string from pt_nb column\n  mutate(pt_nb = str_remove_all(pt_nb, \"pt\")) |&gt;\n  # keep distinct rows\n  distinct() |&gt;\n  # pivot to wide format\n  pivot_wider(id_cols = id:pt_nb, names_from = \"xy\", values_from = \"value\")\n\n# Subset us_clean data for type 2 split\nus_clean_type2 &lt;- us_clean |&gt;\n  # filter data\n  filter(split_type == 2) |&gt;\n  # create new columns to keep points needed for plot\n  mutate(pt1_x = long[pt_nb == 1], pt1_y = lat[pt_nb == 1],\n         pt2_x = unique(split_x2), pt2_y = unique(split_y),\n         pt3_x = unique(split_x1), pt3_y = unique(split_y),\n         pt4_x = pt1_x, pt4_y = pt1_y) |&gt;\n  # select columns\n  select(id, pt1_x:pt4_y) |&gt;\n  # ungroup data\n  ungroup() |&gt;\n  # pivot to long format\n  pivot_longer(cols = -id, names_to = \"pt\", values_to = \"value\") |&gt;\n  # separate \"pt\" column\n  separate(col = pt, into = c(\"pt_nb\", \"xy\"), sep = \"_\") |&gt;\n  # remove \"pt\" string from pt_nb column\n  mutate(pt_nb = str_remove_all(pt_nb, \"pt\")) |&gt;\n  # keep distinct rows\n  distinct() |&gt;\n  # pivot to wide format\n  pivot_wider(id_cols = id:pt_nb, names_from = \"xy\", values_from = \"value\")\n\n\nWe calculate the coordinates of each hexagon‚Äôs centre to add text labels:\n\n# Calculate centres of polygons to plot state labels\ncentres &lt;- gCentroid(us_hex, byid = TRUE) |&gt;\n  as_tibble()\n\nlabels &lt;- us_hex@data$iso3166_2\n\nhex_labels &lt;- tibble(id = labels,\n                     centres) |&gt;\n  filter(id != \"DC\")\n\n# Clean global environment\nrm(centres, labels, land_to_water_ratios, states, us_hex)\n\n\n\n\nCreating the plot\n\n\np &lt;- ggplot() +\n  geom_polygon(data = us_clean, aes(x = long, y = lat, group = id),\n               colour = NA, fill = \"#48bf91\") +\n  geom_polygon(data = us_clean_type1, aes(x = x, y = y, group = id),\n               colour = NA, fill = \"#0076be\") +\n  geom_polygon(data = us_clean_type2, aes(x = x, y = y, group = id),\n               colour = NA, fill = \"#0076be\") +\n  geom_polygon(data = us_clean, aes(x = long, y = lat, group = id),\n               colour = \"white\", fill = NA, linewidth = 0.5) +\n  geom_text(data = hex_labels, aes(x = x, y = y, label = id),\n            family = \"Roboto Condensed\", colour = \"black\", size = 16) +\n  coord_map() +\n  labs(title = \"&lt;span style='color:#48bf91;'&gt;Land&lt;/span&gt; to &lt;span style='color:#0076be;'&gt;water&lt;/span&gt; surface ratios in the U.S.\",\n       caption = \"#TidyTuesday 2023 week 31 | Data from Wikipedia | Jonathan Kitt\") +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"black\", colour = NA),\n        plot.background = element_rect(fill = \"black\", colour = NA),\n        plot.title = element_markdown(family = \"Bangers\", size = 90,\n                                      hjust = 0.5, colour = \"white\",\n                                      margin = margin(t = 20)),\n        plot.caption = element_text(family = \"Roboto Condensed\", colour = \"white\", size = 30,\n                                    hjust = 0.5, \n                                    margin = margin(b = 5)))\n\nggsave(\"figs/tt_2023_w31_us.png\", p, dpi = 320, width = 12, height = 6)\n\n\nAnd here‚Äôs the result!"
  },
  {
    "objectID": "posts/2023-08-10-tt-hot-ones/index.html",
    "href": "posts/2023-08-10-tt-hot-ones/index.html",
    "title": "#TidyTuesday 2023 - Week 32",
    "section": "",
    "text": "Introduction\n\nThe #TidyTuesday weekly challenge is organised by the R4DS (R for Data Science) Online Learning Community.\nEvery tuesday throughout the year, participants work on a common dataset and share the plots they create.\nThe dataset for this challenge comes from Wikipedia articles.\n\n\n\nGetting the data\n\nFirst of all, let‚Äôs load the packages we‚Äôll be using :\n\n{tidyverse} to clean the data and create the plots\n{showtext} to change the fonts used\n{patchwork} to combine the plots\n\nIf you don‚Äôt have these packages installed, simply use the install.packages() function.\n\n# Load the packages\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(patchwork)\n\n\nWe also load the fonts we will use in the plots: Bebas Neue for the text and Londrina Shadow for the title.\n\n# Import the fonts\nfont_add_google(\"Bebas Neue\", \"Bebas Neue\")\nfont_add_google(\"Londrina Shadow\", \"Londrina Shadow\")\nshowtext_auto()\n\n\nWe can now download the dataset :\n\n# Download the dataset\nsauces &lt;- read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-08/sauces.csv')\n\n\nThe dataset has 210 observations (rows) and 4 variables (columns).\nEach row represents one sauce used in the show.\nThe 4 variables are:\n\nThe season number (1 to 21)\nThe sauce number (1 to 10, ordered from the least hot to the hottest)\nThe sauce name\nThe Scoville score (sauce rating in Scoville heat units)\n\n\n\n\nCleaning the data\n\nWe use the following code to clean the data:\n\n# Data cleaning and prep - Sauces per season ----\n\n# Scoville scale\nscoville_scale &lt;- tibble(\n  evaluation = c(\"01-Neutral\", \"02-Sweet\", \"03-Warm\", \"04-Spicy\",\n                 \"05-Hot\", \"06-Strong\", \"07-Raging\", \"08-Burning\",\n                 \"09-Torrid\", \"10-Volcanic\", \"11-Explosive\"))\n\n# Count number of sauces for each Scoville scale range per season\nsauces_count &lt;- sauces |&gt;\n  # Create categories for scoville scores\n  mutate(evaluation = case_when(scoville &lt; 100 ~ \"01-Neutral\",\n                                between(scoville, 100, 499) ~ \"02-Sweet\",\n                                between(scoville, 500, 999) ~ \"03-Warm\",\n                                between(scoville, 1000, 1499) ~ \"04-Spicy\",\n                                between(scoville, 1500, 2499) ~ \"05-Hot\",\n                                between(scoville, 2500, 4999) ~ \"06-Strong\",\n                                between(scoville, 5000, 14999) ~ \"07-Raging\",\n                                between(scoville, 15000, 29999) ~ \"08-Burning\",\n                                between(scoville, 30000, 49999) ~ \"09-Torrid\",\n                                between(scoville, 50000, 99999) ~ \"10-Volcanic\",\n                                scoville &gt;= 100000 ~ \"11-Explosive\")) |&gt;\n  # Count number of occurences per season and evaluation\n  count(season, evaluation) |&gt;\n  # Add full Scoville scale\n  right_join(scoville_scale) |&gt;\n  # Add non-existing scoville categories and fill empty cells with 0\n  complete(season, evaluation, fill = list(n = 0)) |&gt;\n  # Remove NAs\n  filter(!is.na(season))\n\n# p1 - Background\np1_bg &lt;- scoville_scale |&gt;\n  # Coordinates for rectangles\n  mutate(x1 = 0, x2 = 4, x3 = 46,\n         y1 = seq(0, 20, 2), y2 = seq(2, 22, 2)) |&gt;\n  # Split evaluation column into grade + evaluation\n  separate(evaluation, into = c(\"grade\", \"evaluation\"))\n\n# p1 - Grid\np1_grid &lt;- tibble(x0 = seq(4, 46, 2),\n                  x1 = x0,\n                  y0 = 0,\n                  y1 = 22)\n\n# p1 - Sauce count\np1_count &lt;- sauces_count |&gt;\n  # Split evaluation column into grade + evaluation\n  separate(evaluation, into = c(\"grade\", \"evaluation\")) |&gt;\n  # Add coordinates\n  mutate(y = rep(seq(1, 21, 2), times = 21)) |&gt;\n  # Order by grade and season\n  arrange(grade, season) |&gt;\n  # Add coordinates\n  mutate(x = rep(seq(5, 45, 2), times = 11)) |&gt;\n  # Remove empty rows\n  filter(n != 0)\n\n# p1 - Axis y text\np1_y_labels &lt;- tibble(x = -0.5,\n                      y = seq(2, 20, 2),\n                      score = c(\"100\", \"500\", \"1,000\", \"1,500\", \"2,500\", \"5,000\",\n                                \"15,000\", \"30,000\", \"50,000\", \"100,000\"))\n\n# Data cleaning and prep - Total score per season ----\n\n# p2 - scores\np2_scores &lt;- sauces |&gt;\n  # Calculate cumulative Scoville score for all 10 sauces per season\n  summarise(total = sum(scoville), .by = season) |&gt;\n  # Add coordinates + round to thousands of units\n  mutate(x = seq(5, 45, 2),\n         total_thsd = plyr::round_any(total, 1000) / 1000)\n\n# p2 - x axis labels\np2_x_labels &lt;- tibble(x = c(2, seq(5, 45, 2)),\n                      y = 3800,\n                      label = c(\"Season #\", 1:21))\n\n# p2 - text\np2_text &lt;- tibble(x = -0.95,\n                  y = c(2600, 2200, 1800, 1400),\n                  label = c(\"Overall Scoville\",\n                            \"heat score for all\",\n                            \"10 sauces (in 1,000s\",\n                            \"of units)\"))\n\n\n\n\nCreating the plot\n\nFirst we create a vector with custom colours:\n\ncustom_cols &lt;- c(\"Neutral\" = \"#86ff00\",\n                 \"Sweet\" = \"#bcff00\",\n                 \"Warm\" = \"#ddfa00\",\n                 \"Spicy\" = \"#edeb00\",\n                 \"Hot\" = \"#eecb00\",\n                 \"Strong\" = \"#ffbf03\",\n                 \"Raging\" = \"#ff9000\",\n                 \"Burning\" = \"#ff6100\",\n                 \"Torrid\" = \"#fe3000\",\n                 \"Volcanic\" = \"#ee0000\",\n                 \"Explosive\" = \"#790200\")\n\n\nWe then create the first plot:\n\n# Create plot - p1 ----\n\np1 &lt;- ggplot() +\n  geom_rect(data = p1_bg,\n            aes(xmin = x1, xmax = x2, ymin = y1, ymax = y2,\n                fill = evaluation),\n            show.legend = FALSE) +\n  geom_rect(data = p1_bg,\n            aes(xmin = x2, xmax = x3, ymin = y1, ymax = y2,\n                fill = evaluation),\n            alpha = 0.5, show.legend = FALSE) +\n  geom_segment(data = p1_grid,\n               aes(x = x0, xend = x1, y = y0, yend = y1)) +\n  geom_text(data = p1_bg,\n            aes(x = 2, y = y1 + 1, label = evaluation),\n            colour = \"black\", family = \"Bebas Neue\", size = 14) +\n  geom_text(data = p1_count,\n            aes(x = x, y = y, label = n),\n            colour = \"white\", family = \"Bebas Neue\", size = 14) +\n  geom_text(data = p1_y_labels,\n            aes(x = x, y = y, label = score),\n            size = 12, hjust = 1, colour = \"white\") +\n  geom_text(aes(x = 2, y = 23.5, label = \"Scoville scale\"),\n            family = \"Bebas Neue\", size = 16, hjust = 0.5, colour = \"white\") +\n  scale_fill_manual(values = custom_cols) +\n  xlim(-1, 46) +\n  labs(title = \"Number of sauces used\") +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"black\"),\n        plot.background = element_rect(fill = \"black\"),\n        plot.title = element_text(family = \"Bebas Neue\", colour = \"white\",\n                                  size = 60, hjust = 0.5, margin = margin(t = 20)))\n\n\nWe now create the second plot:\n\n# Create plot - p2 ----\n\np2 &lt;- ggplot() +\n  geom_rect(data = p2_scores,\n             aes(xmin = x - 0.85, xmax = x + 0.85,\n                 ymin = 0, ymax = total_thsd),\n            fill = \"#edeb00\") +\n  geom_text(data = p2_scores,\n            aes(x = x, y = total_thsd - 160, label = total_thsd),\n            family = \"Bebas Neue\", colour = \"black\", size = 18) +\n  geom_text(data = p2_x_labels,\n            aes(x = x, y = y, label = label),\n            family = \"Bebas Neue\", colour = \"white\", size = 18) +\n  geom_text(data = p2_text,\n            aes(x = x, y = y, label = label),\n            family = \"Bebas Neue\", colour = \"white\", size = 20,\n            hjust = 0) +\n  xlim(-1, 46) +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"black\"),\n        plot.background = element_rect(fill = \"black\"))\n\n\nWe use the {patchwork} package to assemble the plots:\n\n# Assemble plots\np &lt;- p1 / p2 +\n  plot_annotation(title = \"Hot Ones\",\n                  caption = \"#TidyTuesday 2023 week 32 | Data from Wikipedia | Jonathan Kitt\",\n                  theme = theme(panel.background = element_rect(fill = \"black\", colour = \"black\"),\n                                plot.background = element_rect(fill = \"black\", colour = \"black\"),\n                                plot.title = element_text(family = \"Londrina Shadow\",\n                                                          size = 125, hjust = 0.5,\n                                                          colour = \"#edeb00\",\n                                                          margin = margin(t = 10)),\n                                plot.caption = element_text(size = 20, colour = \"white\", hjust = 0.5)))\n\n# Export plot\n\nggsave(\"figs/tt_2023_w32_hot_ones.png\", p, dpi = 320, width = 12, height = 6)\n\n\nAnd here‚Äôs the result!"
  },
  {
    "objectID": "posts/2023-08-29-tt-fair-use/index.html",
    "href": "posts/2023-08-29-tt-fair-use/index.html",
    "title": "#TidyTuesday 2023 - Week 35",
    "section": "",
    "text": "Thanls to Dan Oehm for sharing his tips on addind icons in the script titles!\n\nIntroduction\n\nThe #TidyTuesday weekly challenge is organised by the R4DS (R for Data Science) Online Learning Community.\nEvery tuesday throughout the year, participants work on a common dataset and share the plots they create.\nThe dataset for this challenge comes from the U.S. Copyright Office Fair Use Index.\n\n\n\nGetting the data\n\nFirst of all, let‚Äôs load the packages we‚Äôll be using :\n\n{tidyverse} to clean the data and create the plots\n{showtext} to change the fonts used\n{ggtext} to use colours in the title\n\nIf you don‚Äôt have these packages installed, simply use the install.packages() function.\n\n# üì¶ Load packages ----\n\nlibrary(tidyverse)\nlibrary(showtext)\nlibrary(ggtext)\n\n\nWe also load the fonts we will use in the plots: Bebas Neue for the text and Londrina Shadow for the title.\n\n# üî§ Import fonts ----\n\nfont_add_google(\"Roboto Condensed\", \"Roboto Condensed\")\nshowtext_auto()\n\n\nWe can now download the dataset :\n\n# ‚¨áÔ∏è Import the dataset ----\n\nfair_use_cases &lt;- readr::read_csv(\"https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2023/2023-08-29/fair_use_cases.csv\")\n\n\nThe dataset has 251 observations (rows) and 7 variables (columns).\n\n\n\nCleaning the data\n\nWe use the following code to clean the data:\n\n# üßπ  Clean the data ----\n\nd &lt;- fair_use_cases |&gt;\n  # keep years 2013-2022\n  filter(year &gt;= 2013) |&gt;\n  # count number of found/not found cases per year\n  count(year, fair_use_found) |&gt;\n  # repeat each row n times (n = nb of occurences)\n  uncount(n) |&gt;\n  # create a row index\n  mutate(case_id = 1:n(), .by = c(year, fair_use_found)) |&gt;\n  # use negative values for \"not found\" cases\n  mutate(y = case_when(fair_use_found == TRUE ~ case_id,\n                       TRUE ~ -case_id))\n\n\n\n\nCreating the plot\n\nWe use the following code to create the plot:\n\np &lt;- ggplot(data = d) +\n  geom_point(aes(x = year, y = y,\n                 colour = fair_use_found),\n             shape = 21, size = 6,\n             show.legend = FALSE) +\n  geom_text(aes(x = year, y = y,\n                colour = fair_use_found),\n            label = \"C\",\n            family = \"Roboto Condensed\", size = 12,\n            show.legend = FALSE) +\n  geom_text(aes(x = year, y = 0, label = year),\n            family = \"Roboto Condensed\", size = 15,\n            colour = \"white\") +\n  scale_colour_manual(values = c(\"#fd574a\", \"#2eed91\")) +\n  labs(title = \"Number of fair use court cases in the U.S. (2013-2022)\",\n       subtitle = \"Colours indicate whether fair use was&lt;span style='color:#2eed91;'&gt; found&lt;/span&gt; or &lt;span style='color:#fd574a;'&gt;not found&lt;/span&gt; by the court\",\n       caption = \"#TidyTuesday 2023 week 35 | Data from the U.S. Copyright Office Fair Use Index | Jonathan Kitt\") +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"black\", colour = \"black\"),\n        plot.background = element_rect(fill = \"black\", colour = \"black\"),\n        plot.title = element_markdown(family = \"Roboto Condensed\",\n                                      colour = \"white\", size = 75,\n                                      margin = margin(t = 20, l = 20)),\n        plot.subtitle = element_markdown(family = \"Roboto Condensed\",\n                                         colour = \"white\", size = 50,\n                                         margin = margin(t= 5, l = 20)),\n        plot.caption = element_text(family = \"Roboto Condensed\",\n                                    colour = \"white\", size = 30,\n                                    hjust = 0.5, margin = margin(t = 10, b = 10)))\n\n\nWe now create the second plot:\n\n# ‚úèÔ∏è Create the plot ----\n\np2 &lt;- ggplot() +\n  geom_rect(data = p2_scores,\n             aes(xmin = x - 0.85, xmax = x + 0.85,\n                 ymin = 0, ymax = total_thsd),\n            fill = \"#edeb00\") +\n  geom_text(data = p2_scores,\n            aes(x = x, y = total_thsd - 160, label = total_thsd),\n            family = \"Bebas Neue\", colour = \"black\", size = 18) +\n  geom_text(data = p2_x_labels,\n            aes(x = x, y = y, label = label),\n            family = \"Bebas Neue\", colour = \"white\", size = 18) +\n  geom_text(data = p2_text,\n            aes(x = x, y = y, label = label),\n            family = \"Bebas Neue\", colour = \"white\", size = 20,\n            hjust = 0) +\n  xlim(-1, 46) +\n  theme_void() +\n  theme(panel.background = element_rect(fill = \"black\"),\n        plot.background = element_rect(fill = \"black\"))\n\n# üíæ Export plot ----\n\nggsave(\"figs/tt_2023_w35_fair_use.png\", p, dpi = 320, width = 12, height = 6)\n\n\nAnd here‚Äôs the result!"
  }
]